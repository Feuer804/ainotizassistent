# OpenRouter API Integration - Quick Start

## Ãœbersicht

Umfassende OpenRouter API Integration fÃ¼r Swift-basierte LLM-Anwendungen mit erweiterten Features fÃ¼r Enterprise-Anwendungen.

## Dateien

### 1. OpenRouterClient.swift
- **Hauptklasse fÃ¼r OpenRouter API**
- Model Management und dynamisches Laden
- Cost Tracking pro Modell
- Performance Monitoring
- Failover-Strategien
- Load Balancing
- Batch Processing

### 2. LLMProvider.swift
- **Unified Interface fÃ¼r alle LLM-Provider**
- OpenAI, OpenRouter, Anthropic UnterstÃ¼tzung
- Intelligente Model Selection
- Provider-Abstraktion
- Cross-Provider Analytics

## Schnellstart

```swift
import Foundation

// OpenRouter Client initialisieren
let client = OpenRouterClient.shared

// Models laden
await client.loadModels()

// Chat Message senden
let messages = [["role": "user", "content": "Hallo!"]]
let response = try await client.sendChatMessage(messages: messages)
print(response.choices.first?.message.content ?? "")

// Mit Unified Provider
let unifiedProvider = UnifiedLLMProvider.shared
let task = LLMTask.analysis
let model = unifiedProvider.selectOptimalModel(for: task)
let request = LLMRequest(prompt: "Analysiere...", model: model!)
let response = try await unifiedProvider.generateResponse(for: request)
```

## Hauptfeatures

### âœ… Model Selection
- Dynamisches Laden von OpenRouter Models
- Filterung nach Provider und Capabilities
- Intelligente Modellauswahl

### âœ… Cost Tracking
- Detaillierte Kostenverfolgung pro Modell
- Usage Analytics mit ZeitrÃ¤umen
- Cost-OptimierungsvorschlÃ¤ge

### âœ… Failover Mechanisms
- Round Robin, Least Latency, Most Reliable, Cost Optimized
- Custom Failover-Strategien
- Automatische Provider-Wechsel

### âœ… Load Balancing
- Intelligentes Load Balancing zwischen Providers
- Request-Count Tracking
- Performance-basierte Auswahl

### âœ… Performance Monitoring
- Response Time Tracking
- Success Rate Monitoring
- Quality Score Berechnung
- Tokens-per-Second Messungen

### âœ… Custom Headers & Authentication
- API Key Management
- Custom Headers Support
- HTTP-Referer und X-Title
- Rate Limiting (100 Requests/Minute)

### âœ… Batch Processing
- Batch-Requests Support
- Concurrent Processing
- Chunked Processing
- Batch-Response-Aggregation

### âœ… Usage Analytics
- Cross-Provider Analytics
- Cost-Efficiency Tracking
- Performance-Vergleiche
- Optimierungsempfehlungen

## API-Key Setup

```bash
# In Environment Variables setzen:
OPENROUTER_API_KEY=your_api_key_here
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
```

## Erweiterte Beispiele

### Failover mit mehreren Modellen
```swift
let preferredModels = [gpt4Model, claudeModel, llamaModel]
let response = try await client.sendWithFailover(
    messages: messages,
    preferredModels: preferredModels
)
```

### Batch Processing
```swift
let batchRequests = [
    BatchRequest(requests: batchMessages, model: selectedModel)
]
let results = try await client.processBatchRequests(batchRequests)
```

### Analytics
```swift
let analytics = client.getUsageAnalytics()
for (modelId, stats) in analytics {
    print("Cost: $\(stats.totalCost), Tokens: \(stats.totalTokens)")
}
```

## Dokumentation

VollstÃ¤ndige Dokumentation in `OpenRouter_Implementierungshandbuch.md`

## UnterstÃ¼tzte Provider

- âœ… **OpenRouter** (VollstÃ¤ndig implementiert)
- âœ… **OpenAI** (Grundlegende Integration)
- ðŸ”„ **Anthropic** (Vorbereitet)
- ðŸ”„ **Hugging Face** (Geplant)
- ðŸ”„ **Cohere** (Geplant)

## Lizenz

MIT License - Frei fÃ¼r kommerzielle und private Nutzung.

---

**Status:** âœ… Produktionsreif  
**Letzte Aktualisierung:** 2025-10-31  
**Version:** 1.0.0